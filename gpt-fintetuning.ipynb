{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning GPT-2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanshdhar/Desktop/AIDS/nlp/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Normalize Unicode characters (Replace common Unicode characters)\n",
    "    text = text.replace(\"\\u201c\", '\"').replace(\"\\u201d\", '\"').replace(\"\\u2018\", \"'\").replace(\"\\u2019\", \"'\")\n",
    "    text = text.replace(\"\\u2013\", \"-\").replace(\"\\u2026\", \"...\").replace(\"\\u2022\", \"*\")  # Handle en dash, ellipsis, bullet points\n",
    "    \n",
    "    # 2. Decode HTML entities (e.g., \"&amp;\" becomes \"&\")\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # 3. Remove non-ASCII characters (if necessary, using a more aggressive approach)\n",
    "    text = ''.join([c for c in text if ord(c) < 128])  # Keep only ASCII characters (lower-level cleaning)\n",
    "    \n",
    "    # 4. Remove unwanted symbols: Strip any non-letter, non-digit, non-punctuation characters\n",
    "    text = re.sub(r'[^\\w\\s.,!?\\'\";:()-]', '', text)  # Keep common punctuation but remove others\n",
    "    \n",
    "    # 5. Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # 6. Remove leading and trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    # 7. Ensure proper sentence ending (optional, can be customized)\n",
    "    if text and text[-1] not in ['.', '!', '?']:\n",
    "        text += '.'  # Add period if no punctuation at the end\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to structure the jokes\n",
    "def structure_jokes_from_json(file_path):\n",
    "    \"\"\"\n",
    "    Structure jokes from the original JSON file containing 'title' and 'body'.\n",
    "    Assumes title is the question/prompt and body is the punchline/response.\n",
    "    \n",
    "    Args:\n",
    "    - file_path (str): Path to the original JSON file containing the jokes.\n",
    "    \n",
    "    Returns:\n",
    "    - list of structured jokes in the form of [{\"text\": \"title <|sep|> body <|endofjoke|>\"}]\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    structured_jokes = []\n",
    "    for entry in data:\n",
    "        title = clean_text(entry[\"title\"])\n",
    "        body = clean_text(entry[\"body\"])\n",
    "        \n",
    "        # Skip jokes that are too short\n",
    "        if len(title.split()) < 3 or len(body.split()) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Structure joke as 'title <|sep|> body <|endofjoke|>'\n",
    "        joke = f\"{title} <|sep|> {body} <|endofjoke|>\"\n",
    "        structured_jokes.append({\"text\": joke})\n",
    "    \n",
    "    return structured_jokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize\n",
    "Used the GPT2 tokenizer\n",
    "\n",
    "Max_length used = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Function to tokenize the jokes\n",
    "def tokenize_data(dataset, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenize the joke data for GPT-2 model.\n",
    "    \n",
    "    Args:\n",
    "    - dataset (list): List of jokes to be tokenized.\n",
    "    - tokenizer (GPT2Tokenizer): The GPT-2 tokenizer.\n",
    "    \n",
    "    Returns:\n",
    "    - tokenized dataset\n",
    "    \"\"\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Set the pad token to be the end-of-text token\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        # Tokenize and ensure tensors are returned\n",
    "        return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "    # Convert the list of structured jokes into a Dataset object from Hugging Face\n",
    "    dataset = Dataset.from_list(dataset)\n",
    "    \n",
    "    # Tokenize the entire dataset\n",
    "    return dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])  # Remove original text column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "def fine_tune_gpt2(file_path, model_output_dir, epochs, batch_size, max_length):\n",
    "    # Load the dataset and tokenizer\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    structured_jokes = structure_jokes_from_json(file_path)\n",
    "    dataset = tokenize_data(structured_jokes, tokenizer)  # Ensure this returns tokenized dataset\n",
    "    \n",
    "    # Load the model\n",
    "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "    \n",
    "    # Set the training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        logging_dir=\"./logs\",\n",
    "        save_steps=1000,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "    )\n",
    "    \n",
    "    from torch.utils.data import DataLoader\n",
    "    import torch\n",
    "\n",
    "    # Custom collate function to handle the dataset\n",
    "    def collate_fn(batch):\n",
    "        input_ids = torch.stack([torch.tensor(x['input_ids']) for x in batch])\n",
    "        attention_mask = torch.stack([torch.tensor(x['attention_mask']) for x in batch])\n",
    "        labels = input_ids.clone()  # Shift input_ids for causal language modeling\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        data_collator=collate_fn,  # Use the collate function here\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the fine-tuned model and tokenizer\n",
    "    model.save_pretrained(model_output_dir)\n",
    "    tokenizer.save_pretrained(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 155493/155493 [00:25<00:00, 6206.44 examples/s]\n",
      "                                         \n",
      "  0%|          | 0/38874 [03:58<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2326, 'grad_norm': 1.4769753217697144, 'learning_rate': 4.935689664042805e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [05:41<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2066, 'grad_norm': 2.4955990314483643, 'learning_rate': 4.87137932808561e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [07:25<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2018, 'grad_norm': 1.7053908109664917, 'learning_rate': 4.807068992128415e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [09:07<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.201, 'grad_norm': 1.6881585121154785, 'learning_rate': 4.74275865617122e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [10:51<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1722, 'grad_norm': 2.1805477142333984, 'learning_rate': 4.678448320214025e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [12:32<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1299, 'grad_norm': 2.1538000106811523, 'learning_rate': 4.61413798425683e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [14:13<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1285, 'grad_norm': 1.8449656963348389, 'learning_rate': 4.549827648299635e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [15:54<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1653, 'grad_norm': 1.6678621768951416, 'learning_rate': 4.48551731234244e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [17:36<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.148, 'grad_norm': 2.092423439025879, 'learning_rate': 4.421206976385245e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [19:17<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.15, 'grad_norm': 1.3931502103805542, 'learning_rate': 4.35689664042805e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [20:59<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1354, 'grad_norm': 1.550413966178894, 'learning_rate': 4.292586304470855e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [22:40<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1461, 'grad_norm': 0.9359981417655945, 'learning_rate': 4.2282759685136595e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [24:23<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.138, 'grad_norm': 1.2201206684112549, 'learning_rate': 4.163965632556465e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [26:06<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0849, 'grad_norm': 1.0785069465637207, 'learning_rate': 4.0996552965992696e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [27:44<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1096, 'grad_norm': 1.6145451068878174, 'learning_rate': 4.035344960642074e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [29:16<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1336, 'grad_norm': 0.8259145021438599, 'learning_rate': 3.97103462468488e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [30:50<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1306, 'grad_norm': 1.0573372840881348, 'learning_rate': 3.9067242887276844e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [32:22<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1405, 'grad_norm': 0.967609703540802, 'learning_rate': 3.84241395277049e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [33:55<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1241, 'grad_norm': 1.5707956552505493, 'learning_rate': 3.7781036168132945e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [35:27<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0818, 'grad_norm': 0.9450043439865112, 'learning_rate': 3.713793280856099e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [37:00<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1175, 'grad_norm': 1.4024978876113892, 'learning_rate': 3.6494829448989046e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [38:31<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1142, 'grad_norm': 1.8105716705322266, 'learning_rate': 3.585172608941709e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [40:04<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0848, 'grad_norm': 1.8111623525619507, 'learning_rate': 3.520862272984514e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [41:36<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0697, 'grad_norm': 1.3567249774932861, 'learning_rate': 3.4565519370273194e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [43:09<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0563, 'grad_norm': 1.0733556747436523, 'learning_rate': 3.392241601070124e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [44:41<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1066, 'grad_norm': 1.3575106859207153, 'learning_rate': 3.327931265112929e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [46:14<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1018, 'grad_norm': 1.4190309047698975, 'learning_rate': 3.263620929155734e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [47:46<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0853, 'grad_norm': 1.3183685541152954, 'learning_rate': 3.199310593198539e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [49:19<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1045, 'grad_norm': 1.1297410726547241, 'learning_rate': 3.1350002572413436e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [50:51<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0681, 'grad_norm': 1.7300455570220947, 'learning_rate': 3.070689921284149e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [52:24<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.096, 'grad_norm': 1.666089653968811, 'learning_rate': 3.0063795853269537e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [53:56<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0723, 'grad_norm': 1.381811499595642, 'learning_rate': 2.9420692493697588e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [55:28<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0839, 'grad_norm': 1.5768322944641113, 'learning_rate': 2.8777589134125638e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [57:00<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0776, 'grad_norm': 1.0329643487930298, 'learning_rate': 2.813448577455369e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [58:33<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0427, 'grad_norm': 1.422408938407898, 'learning_rate': 2.7491382414981736e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                         \n",
      "  0%|          | 0/38874 [1:00:05<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0634, 'grad_norm': 1.4973145723342896, 'learning_rate': 2.6848279055409786e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:01:38<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0644, 'grad_norm': 1.6034085750579834, 'learning_rate': 2.6205175695837837e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:03:10<?, ?it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.053, 'grad_norm': 1.7707070112228394, 'learning_rate': 2.5562072336265887e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:04:43<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0732, 'grad_norm': 0.8504739999771118, 'learning_rate': 2.4918968976693934e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:06:15<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.049, 'grad_norm': 1.1779659986495972, 'learning_rate': 2.4275865617121985e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:07:48<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0871, 'grad_norm': 1.1296643018722534, 'learning_rate': 2.3632762257550035e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:09:20<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0512, 'grad_norm': 0.9055140018463135, 'learning_rate': 2.2989658897978082e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:10:53<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0894, 'grad_norm': 1.0274111032485962, 'learning_rate': 2.2346555538406133e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:12:24<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0758, 'grad_norm': 1.4623013734817505, 'learning_rate': 2.1703452178834183e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:13:57<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0569, 'grad_norm': 1.0185227394104004, 'learning_rate': 2.1060348819262234e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:15:29<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0686, 'grad_norm': 1.8561128377914429, 'learning_rate': 2.041724545969028e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:17:02<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0346, 'grad_norm': 1.0581450462341309, 'learning_rate': 1.977414210011833e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:18:34<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0685, 'grad_norm': 0.9050993323326111, 'learning_rate': 1.9131038740546382e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:20:07<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0618, 'grad_norm': 0.9520531892776489, 'learning_rate': 1.848793538097443e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:21:39<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0558, 'grad_norm': 0.9051138758659363, 'learning_rate': 1.784483202140248e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:23:12<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0895, 'grad_norm': 1.3443220853805542, 'learning_rate': 1.720172866183053e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:24:44<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0433, 'grad_norm': 1.8273134231567383, 'learning_rate': 1.655862530225858e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:26:16<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0712, 'grad_norm': 0.8624415993690491, 'learning_rate': 1.5915521942686627e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:27:48<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0609, 'grad_norm': 1.157494068145752, 'learning_rate': 1.5272418583114678e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:29:21<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0657, 'grad_norm': 1.504683256149292, 'learning_rate': 1.4629315223542728e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:30:53<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0418, 'grad_norm': 1.0027798414230347, 'learning_rate': 1.3986211863970777e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:32:26<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0585, 'grad_norm': 1.1035927534103394, 'learning_rate': 1.3343108504398828e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:33:58<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.055, 'grad_norm': 1.3983980417251587, 'learning_rate': 1.2700005144826877e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:35:31<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0327, 'grad_norm': 1.463358759880066, 'learning_rate': 1.2056901785254927e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:37:03<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0587, 'grad_norm': 1.3753905296325684, 'learning_rate': 1.1413798425682977e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:38:35<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0157, 'grad_norm': 1.3243924379348755, 'learning_rate': 1.0770695066111026e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:40:07<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0829, 'grad_norm': 1.5162155628204346, 'learning_rate': 1.0127591706539077e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:41:40<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0849, 'grad_norm': 1.1967121362686157, 'learning_rate': 9.484488346967126e-06, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:43:12<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0426, 'grad_norm': 1.53708016872406, 'learning_rate': 8.841384987395174e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:44:45<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0481, 'grad_norm': 1.3926535844802856, 'learning_rate': 8.198281627823225e-06, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:46:17<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0857, 'grad_norm': 1.0185165405273438, 'learning_rate': 7.5551782682512745e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:47:50<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0464, 'grad_norm': 0.9658646583557129, 'learning_rate': 6.912074908679324e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:49:21<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0444, 'grad_norm': 1.1222537755966187, 'learning_rate': 6.268971549107373e-06, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:50:54<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0831, 'grad_norm': 0.928777277469635, 'learning_rate': 5.6258681895354226e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:52:26<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0458, 'grad_norm': 1.2031396627426147, 'learning_rate': 4.982764829963471e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:53:59<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0248, 'grad_norm': 1.236107349395752, 'learning_rate': 4.339661470391521e-06, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:55:31<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0585, 'grad_norm': 1.2515966892242432, 'learning_rate': 3.6965581108195706e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:57:04<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0378, 'grad_norm': 1.3884307146072388, 'learning_rate': 3.0534547512476207e-06, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [1:58:36<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0566, 'grad_norm': 2.2116827964782715, 'learning_rate': 2.4103513916756703e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [2:00:09<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0646, 'grad_norm': 1.098183274269104, 'learning_rate': 1.7672480321037198e-06, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [2:01:40<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0224, 'grad_norm': 1.3034898042678833, 'learning_rate': 1.1241446725317694e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "  0%|          | 0/38874 [2:03:13<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0358, 'grad_norm': 1.5755958557128906, 'learning_rate': 4.81041312959819e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \n",
      "100%|██████████| 38874/38874 [2:02:04<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 7324.2511, 'train_samples_per_second': 21.23, 'train_steps_per_second': 5.308, 'train_loss': 1.086230080627074, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune GPT-2 using the original JSON file containing jokes\n",
    "fine_tune_gpt2(\n",
    "    file_path=\"../data/reddit_jokes.json\",  # Path to your original JSON file\n",
    "    model_output_dir=\"../gpt2-joke-model\",  # Directory to save the fine-tuned model\n",
    "    epochs=1,  # Number of training epochs\n",
    "    batch_size=4,  # Batch size\n",
    "    max_length=128  # Maximum token length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the difference between a black man and a pizza? <|sep|> A pizza can feed a family of four. <|endofjoke|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"../gpt2-joke-model\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"../gpt2-joke-model\")\n",
    "\n",
    "# Use the model\n",
    "text = \"What is the difference between\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length = 100)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model generates offensive and racist jokes often, because it was trained on the reddit jokes only."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
